# ======== STOR566: Yiwen run (ResNet18 + HiLoViT, CIFAR-10, 2 epochs) ========
# 0) Setup
!pip -q install timm
!git clone -q https://github.com/ziplab/LITv2.git

import os, time, random, numpy as np
import torch, torch.nn as nn, torch.nn.functional as F
import torchvision, torchvision.transforms as T
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
import pandas as pd
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
import sys; sys.path.append('/content/LITv2')
from hilo import HiLo  # official HiLo attention

def set_seed(seed=2025):
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = True
set_seed(2025)

def get_cifar_loaders(img_size=32, batch_size=128, num_workers=2):
    norm = T.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))
    train_tf = T.Compose([T.RandomCrop(img_size, padding=4), T.RandomHorizontalFlip(), T.ToTensor(), norm])
    test_tf  = T.Compose([T.ToTensor(), norm])
    train_ds = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=train_tf)
    test_ds  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tf)
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
    return train_loader, test_loader, 10

def get_resnet18(num_classes=10):
    m = torchvision.models.resnet18(weights=None)
    m.fc = nn.Linear(m.fc.in_features, num_classes)
    return m

# ---- Minimal ViT with HiLo blocks ----
class PatchEmbed(nn.Module):
    def __init__(self, img_size=32, patch_size=4, in_ch=3, embed_dim=192):
        super().__init__()
        self.proj = nn.Conv2d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)
        self.grid = img_size // patch_size
    def forward(self, x):
        x = self.proj(x)               # B,C,H',W'
        x = x.flatten(2).transpose(1,2)  # B,N,C
        return x

class MLP(nn.Module):
    def __init__(self, dim, mlp_ratio=4.0, drop=0.0):
        super().__init__()
        hidden=int(dim*mlp_ratio)
        self.fc1=nn.Linear(dim,hidden); self.fc2=nn.Linear(hidden,dim)
        self.act=nn.GELU(); self.drop=nn.Dropout(drop)
    def forward(self, x):
        x=self.fc1(x); x=self.act(x); x=self.drop(x)
        x=self.fc2(x); x=self.drop(x); return x

class HiLoBlock(nn.Module):
    def __init__(self, dim, num_heads=6, window_size=2, alpha=0.5, drop=0.0, mlp_ratio=4.0):
        super().__init__()
        self.norm1=nn.LayerNorm(dim); self.attn=HiLo(dim, num_heads, window_size, alpha)
        self.norm2=nn.LayerNorm(dim); self.mlp=MLP(dim, mlp_ratio, drop)
        self.drop_path=nn.Identity()
    def forward(self, x, H, W):
        x = x + self.drop_path(self.attn(self.norm1(x), H, W))
        x = x + self.drop_path(self.mlp(self.norm2(x)))
        return x

class HiLoViT(nn.Module):
    def __init__(self, img_size=32, patch_size=4, in_ch=3, num_classes=10,
                 embed_dim=192, depth=6, num_heads=6, window_size=2, alpha=0.5):
        super().__init__()
        self.patch = PatchEmbed(img_size, patch_size, in_ch, embed_dim)
        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))
        self.pos = nn.Parameter(torch.zeros(1, (img_size//patch_size)**2 + 1, embed_dim))
        self.blocks = nn.ModuleList([HiLoBlock(embed_dim, num_heads, window_size, alpha) for _ in range(depth)])
        self.norm = nn.LayerNorm(embed_dim); self.head = nn.Linear(embed_dim, num_classes)
        self.grid = img_size//patch_size
        nn.init.trunc_normal_(self.pos, std=0.02); nn.init.trunc_normal_(self.cls_token, std=0.02)
    def forward(self, x):
        B=x.size(0); x=self.patch(x); cls=self.cls_token.expand(B,-1,-1)
        x=torch.cat([cls,x],1)+self.pos
        for blk in self.blocks: x=blk(x, self.grid, self.grid)
        x=self.norm(x); cls=x[:,0]; return self.head(cls)

@torch.no_grad()
def eval_model(model, loader, criterion):
    model.eval(); total=0; correct=0; loss_sum=0.0
    for x,y in loader:
        x,y = x.to(device), y.to(device)
        with autocast(True):
            logits=model(x); loss=criterion(logits,y)
        pred=logits.argmax(1); correct+=(pred==y).sum().item()
        total+=y.size(0); loss_sum+=loss.item()*y.size(0)
    return {'loss':loss_sum/total,'top1':100.0*correct/total}

def train_one(model, train_loader, test_loader, epochs=2, lr=3e-4, wd=1e-4, name='model', outdir='./exp_outputs_Yiwen'):
    model=model.to(device)
    opt=torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    sched=torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)
    scaler=GradScaler(True); crit=nn.CrossEntropyLoss().to(device)
    hist=[]
    for ep in range(1,epochs+1):
        model.train(); run=0.0; n=0
        for x,y in train_loader:
            x,y=x.to(device),y.to(device)
            opt.zero_grad(set_to_none=True)
            with autocast(True):
                logits=model(x); loss=crit(logits,y)
            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()
            run+=loss.item()*y.size(0); n+=y.size(0)
        sched.step()
        ev=eval_model(model,test_loader,crit)
        row={'epoch':ep,'train_loss':run/n,'test_loss':ev['loss'],'test_top1':ev['top1'],'lr':sched.get_last_lr()[0]}
        hist.append(row); print(f"[{name}] Epoch {ep:02d}  top1={row['test_top1']:.2f}%  loss={row['test_loss']:.4f}")
    os.makedirs(outdir, exist_ok=True)
    df=pd.DataFrame(hist); df.to_csv(os.path.join(outdir,f'history_cifar10_{name}.csv'), index=False)
    return df['test_top1'].max()

def run_and_save():
    train_loader, test_loader, ncls = get_cifar_loaders()
    results=[]
    # ResNet18
    r18=get_resnet18(ncls)
    r18_top1=train_one(r18, train_loader, test_loader, epochs=2, lr=3e-4, wd=1e-4, name='resnet18', outdir='./exp_outputs_Yiwen')
    results.append({'model':'resnet18','best_top1':r18_top1})
    # HiLoViT
    vit=HiLoViT(img_size=32, num_classes=ncls, embed_dim=192, depth=6, num_heads=6, window_size=2, alpha=0.5)
    vit_top1=train_one(vit, train_loader, test_loader, epochs=2, lr=3e-4, wd=1e-4, name='hilovit', outdir='./exp_outputs_Yiwen')
    results.append({'model':'hilovit','best_top1':vit_top1})
    df=pd.DataFrame(results); df.to_csv('./exp_outputs_Yiwen/summary_cifar10_Yiwen.csv', index=False)
    print("\nSaved: ./exp_outputs_Yiwen/summary_cifar10_Yiwen.csv")

# Go!
run_and_save()
