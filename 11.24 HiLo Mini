# ================================================================
#   HiLoViT — mini-ImageNet (HuggingFace)
#   FINAL STABLE VERSION — No CLS, No reshape errors, No collate errors
# ================================================================

# ===== 1. Import uploaded hilo.py =====
import sys, os
sys.path.append("/mnt/data")
from hilo import HiLo
print("Loaded HiLo from /mnt/data/hilo.py ✔")

# ===== 2. Install deps =====
!pip install datasets thop > /dev/null

# ===== 3. Imports =====
import torch
import torch.nn as nn
import torchvision.transforms as T
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler

import numpy as np
import pandas as pd
import random, time, copy

from datasets import load_dataset
from sklearn.metrics import roc_auc_score, f1_score
from thop import profile

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

# ------------------------------------------------
# Config
# ------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

IMG_SIZE = 84
PATCH_SIZE = 7
GRID = IMG_SIZE // PATCH_SIZE   # 12
BATCH_SIZE = 128
EPOCHS = 20
NUM_CLASSES = 100

OUTDIR = "./hilovit_mini_final"
os.makedirs(OUTDIR, exist_ok=True)

# ------------------------------------------------
# Seed
# ------------------------------------------------
def seed_all(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if device == "cuda":
        torch.cuda.manual_seed_all(seed)

seed_all()

# ------------------------------------------------
# Bulletproof ensure_tensor
# ------------------------------------------------
tf_resize = T.Resize((IMG_SIZE, IMG_SIZE))
tf_norm   = T.Normalize((0.485,0.456,0.406),
                         (0.229,0.224,0.225))

def ensure_tensor(img):
    """
    Convert any HF mini-ImageNet entry to Tensor[3,84,84].
    Handles:
    - PIL
    - nested lists
    - grayscale
    - tensors of wrong shape
    - corrupted images → zero image
    """
    try:
        # unwrap nested lists
        while isinstance(img, list):
            img = img[0]

        # PIL
        if hasattr(img, "convert"):
            img = img.convert("RGB")
            img = T.ToTensor()(tf_resize(img))
            img = tf_norm(img)
            return img

        # Tensor
        if torch.is_tensor(img):
            # (H,W) → (1,H,W)
            if img.ndim == 2:
                img = img.unsqueeze(0)

            # grayscale
            if img.ndim == 3 and img.shape[0] == 1:
                img = img.repeat(3,1,1)

            # ensure size
            if img.ndim == 3:
                if img.shape[1] != IMG_SIZE or img.shape[2] != IMG_SIZE:
                    img = tf_resize(img)
                img = tf_norm(img)
                return img

        # corrupted case
        raise Exception("invalid")

    except:
        dummy = torch.zeros(3, IMG_SIZE, IMG_SIZE)
        dummy = tf_norm(dummy)
        return dummy

# ------------------------------------------------
# Custom collate (critical!)
# ------------------------------------------------
def raw_collate_fn(batch):
    images = [item["image"] for item in batch]
    labels = [item["label"] for item in batch]
    return {"image": images, "label": labels}

# ------------------------------------------------
# mini-ImageNet Loader (NO map)
# ------------------------------------------------
def get_mini_imagenet_loaders(batch_size=BATCH_SIZE):
    ds = load_dataset("timm/mini-imagenet")

    train_loader = DataLoader(
        ds["train"],
        batch_size=batch_size,
        shuffle=True,
        collate_fn=raw_collate_fn,
    )
    val_loader = DataLoader(
        ds["validation"],
        batch_size=batch_size,
        shuffle=False,
        collate_fn=raw_collate_fn,
    )

    return train_loader, val_loader, NUM_CLASSES

train_loader, val_loader, num_classes = get_mini_imagenet_loaders()
print("mini-ImageNet loaded:", len(train_loader.dataset), "train")

# ------------------------------------------------
# HiLoViT (no CLS, mean pooling)
# ------------------------------------------------
class PatchEmbed(nn.Module):
    def __init__(self, img_size=84, patch_size=7, embed_dim=192):
        super().__init__()
        self.proj = nn.Conv2d(
            in_channels=3,
            out_channels=embed_dim,
            kernel_size=patch_size,
            stride=patch_size
        )
        self.grid = img_size // patch_size

    def forward(self, x):
        x = self.proj(x)                 # (B,C,12,12)
        B,C,H,W = x.shape
        assert H == W == self.grid
        x = x.flatten(2).transpose(1,2)  # (B,144,C)
        return x, H, W

class MLP(nn.Module):
    def __init__(self, dim, ratio=4.0):
        super().__init__()
        hidden = int(dim * ratio)
        self.fc1 = nn.Linear(dim, hidden)
        self.fc2 = nn.Linear(hidden, dim)
        self.act = nn.GELU()
    def forward(self,x):
        return self.fc2(self.act(self.fc1(x)))

class HiLoBlock(nn.Module):
    def __init__(self, dim, heads=6, win=2, alpha=0.9):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn  = HiLo(dim, num_heads=heads,
                          window_size=win, alpha=alpha)
        self.norm2 = nn.LayerNorm(dim)
        self.mlp   = MLP(dim)
    def forward(self, x, H, W):
        x = x + self.attn(self.norm1(x), H, W)
        x = x + self.mlp(self.norm2(x))
        return x

class HiLoViT(nn.Module):
    def __init__(self,
                 img_size=IMG_SIZE,
                 patch_size=PATCH_SIZE,
                 num_classes=NUM_CLASSES,
                 embed_dim=192,
                 depth=6,
                 num_heads=6,
                 window_size=2,
                 alpha=0.9):
        super().__init__()

        self.patch = PatchEmbed(img_size, patch_size, embed_dim)
        grid = img_size // patch_size
        N = grid * grid

        self.pos = nn.Parameter(torch.zeros(1, N, embed_dim))

        self.blocks = nn.ModuleList([
            HiLoBlock(embed_dim, num_heads, window_size, alpha)
            for _ in range(depth)
        ])

        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Linear(embed_dim, num_classes)

        nn.init.trunc_normal_(self.pos, std=0.02)

    def forward(self, x):
        x, H, W = self.patch(x)   # (B,144,C)
        B,N,C = x.shape

        x = x + self.pos[:, :N, :]
        for blk in self.blocks:
            x = blk(x,H,W)

        x = self.norm(x)
        x = x.mean(dim=1)         # mean pool
        return self.head(x)

# ------------------------------------------------
# Eval
# ------------------------------------------------
def count_params(m):
    return sum(p.numel() for p in m.parameters() if p.requires_grad)

@torch.no_grad()
def eval_epoch(model, loader, criterion):
    model.eval()
    total_loss=0; total_correct=0; total=0
    y_true=[]; y_pred=[]; y_prob=[]

    for batch in loader:
        xs = [ensure_tensor(im) for im in batch["image"]]
        x = torch.stack(xs).to(device)
        y = torch.tensor(batch["label"], dtype=torch.long).to(device)

        with autocast(enabled=(device=="cuda")):
            logits = model(x)
            loss = criterion(logits,y)

        probs = logits.softmax(1)
        pred = probs.argmax(1)

        bs=y.size(0)
        total += bs
        total_loss += loss.item()*bs
        total_correct += (pred==y).sum().item()

        y_true.append(y.cpu())
        y_pred.append(pred.cpu())
        y_prob.append(probs.cpu())

    y_true = torch.cat(y_true).numpy()
    y_pred = torch.cat(y_pred).numpy()
    y_prob = torch.cat(y_prob).numpy()

    try:
        auc = roc_auc_score(y_true,y_prob,multi_class="ovr",average="macro")
    except:
        auc = float("nan")
    f1  = f1_score(y_true,y_pred,average="macro")
    acc = 100 * total_correct / total
    loss = total_loss / total

    return loss, acc, auc, f1

# ------------------------------------------------
# Training loop
# ------------------------------------------------
def train_hilovit():
    model = HiLoViT().to(device)
    print("Params:", count_params(model))

    criterion = nn.CrossEntropyLoss()
    opt = torch.optim.AdamW(model.parameters(), lr=3e-4)
    scaler = GradScaler(enabled=(device=="cuda"))

    history=[]

    for ep in range(1,EPOCHS+1):
        model.train()
        total=0; tr_loss_sum=0; tr_correct=0

        for batch in train_loader:
            xs = [ensure_tensor(im) for im in batch["image"]]
            x = torch.stack(xs).to(device)
            y = torch.tensor(batch["label"], dtype=torch.long).to(device)

            opt.zero_grad()
            with autocast(enabled=(device=="cuda")):
                logits = model(x)
                loss = criterion(logits,y)

            scaler.scale(loss).backward()
            scaler.step(opt)
            scaler.update()

            bs=y.size(0)
            total += bs
            tr_loss_sum += loss.item()*bs
            tr_correct += (logits.argmax(1)==y).sum().item()

        tr_loss = tr_loss_sum/total
        tr_acc  = 100*tr_correct/total

        val_loss,val_acc,auc,f1 = eval_epoch(model,val_loader,criterion)

        print(f"[Epoch {ep}/{EPOCHS}] "
              f"Train {tr_loss:.4f}/{tr_acc:.1f}% | "
              f"Val {val_loss:.4f}/{val_acc:.1f}% | "
              f"AUC {auc:.4f} F1 {f1:.4f}")

        history.append({
            "epoch":ep,
            "train_loss":tr_loss,
            "train_acc":tr_acc,
            "val_loss":val_loss,
            "val_acc":val_acc,
            "val_auc":auc,
            "val_f1":f1,
        })

    pd.DataFrame(history).to_csv(os.path.join(OUTDIR,"hilovit_history.csv"),index=False)
    print("Saved:", os.path.join(OUTDIR,"hilovit_history.csv"))

# ------------------------------------------------
# Run training
# ------------------------------------------------
train_hilovit()
